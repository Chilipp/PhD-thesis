% teleconnections chapter

\Chapter{pyleogrid}{An Ensemble method for Gridding Paleo Proxy Climates}

\label{chp:gridding}

\begin{refsection}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introduction}  \label{sec:gridding-intro}

\begin{itemize}
	\item Why gridding
	\begin{itemize}
		\item Data-Model-Intercomparisons)
		\item Easier to handle
		\item Energy balance, compatibility with models, grid cell (Area) averages
		\item Stability of observation network through time
		\item Not just spatial grid, also regular timestep (problems with pseudo gridding, including time ‘windows’ or ‘slices’
		\item Understanding past climates, different forcings – independent of models (difficult from point-cloud)
		\item Filling the gaps
		\item Spatial scales (Samarthein chironomids etc)
	\end{itemize}
	\item Importance of uncertainties
	\begin{itemize}
		\item Necessary for data comparisons, interpretation skill of the data
		\item Proxy climate reconstruction uncertainties are higher (inverse modelling, not always properly defined (MAT)) than for instrumental data
		\item Age uncertainties can be high (centennial to multi-millennial)
	\end{itemize}
	\item Why Tps (can also use something else, but has been used before)
	\begin{itemize}
		\item Extrapolation to the gaps (Previous work by mauri et al and davis)
		\item Pseudo-gridding (marcott, Marsicek 2018, Margo, 2009, Bartlein et al ?2013) has holes
		\item Data assimiliation (pages2k? Need to look the paper up again) – depends on model
		\item Bayesian data assimiliation (Weitzel 2019) – depends on model
		\item Does not require interpolation of time (Marsicek 2018)
	\end{itemize}
	\item Other
	\item Introducing constraints; climate, training set size, spatial coverage etc
\end{itemize}


\section{Data}  \label{sec:gridding-data}

The ensemble based gridding method is adapted to paleo-climates. In this study, we describe the method using a large set of western Eurasian fossil pollen assemblages that have been transformed to \gls{jja} temperatures. We focus on pollen data because it is the spatially most widely available proxy during the Holocene, but it is important to mention that the reconstruction method is agnostic to the climate proxy, because it does not explicitly use the pollen assemblages but rather alters the standard climate reconstruction method under the aspect of it's methodological uncertainties. As such, the following sections describe the fossil and modern pollen database for this use case (section \ref{sec:gridding-polnet}) and the associated uncertainties of the temperature reconstruction method (section \ref{sec:gridding-mat}) and the dating of the fossil pollen samples (section \ref{sec:gridding-ageunc}).

\subsection{Pollen database}  \label{sec:gridding-polnet}

\begin{figure}
	\includegraphics[width=\linewidth]{gridding-figures/origins.pdf} \\
	\includegraphics[width=\linewidth]{gridding-figures/sitelocs.pdf}
	\caption[Fossil Pollen Database]{Data origins for the fossil POLNET database in western Eurasia (1351 in total). The majority comes from the \gls{epd} and other public datasets, and some sites where obtained through direct communication from the authors and private databases.}
	\label{fig:gridding-fossil}
\end{figure}

The source data for this study is a subset of the latest development version of the POLNET database, a northern hemispheric, sub-tropical collection of pollen assemblages \citep{DavisKaplan2017, SommerDavisChevalierEtAl2019}. The purpose of this database is to generate the source for large-scale climate reconstruction during the Holocene (past 12'000 years) that can be used for model-data comparisons. The subset that we use in this study to describe and develop the gridding method contains fossil and modern pollen assemblages of western Eurasia, a region that has already been under investigation in the previous study by \cite{MauriDavisCollinsEtAl2015}. 

The database contains raw pollen counts from various publicly available and private data sources, in total 1350 datasets with 80500 fossil samples. The majority of the fossil pollen data (see figure \ref{fig:gridding-fossil}) comes from the \gls{epd} (94\%), other publicly available databases \addref[Binney, Cao et al., 2019, ACER database], and PANGAEA. The  rest has been obtained either through private communications from the author\addref[probably not possible...], the private database that has also been used by \cite{MauriDavisCollinsEtAl2015}, and 2 sites have been digitized.

\begin{figure}
	\missingfigure{Modern calibration data (ask Manu)}
	\caption{Modern calibration database}
	\label{fig:gridding-modern}
\end{figure}

The modern calibration dataset (XXXX samples, see figure \ref{fig:gridding-modern}) is mainly based on the version 2 of the \gls{empd} \citep{DavisZanonCollinsEtAl2013}\todo{Describe origins of modern calibration data, link back to chapter \ref{chp:empd}}. 


\subsection{Sample site: Tigalmamine} \label{sec:gridding-sample-site}

\begin{figure}
	\captionsetup{width=1.2\linewidth}
	\includegraphics[width=\linewidth]{gridding-figures/tigalmamine-analogue-map.pdf} \\
	\includegraphics[width=\linewidth]{gridding-figures/tigalmamine-analogue-climates.pdf}
	\caption[Climate analogues of the Tigalmamine site]{Climate analogues of the Tigalmamine site (red cross). Every circle corresponds to one modern analogue that was one of the fifties closest analogues in at least one sample within the Tigalmamine dataset. The color-coding of each circle is based it's corresponding country (see legend at the top). The marker size in the top plot depends on the usage of the sample as modern analogue. The larger the marker, the more samples in the Tigalmamine dataset use it as modern analogue. Tiny crosses in the map represent the rest of the modern calibration data. The lower plot shows the summer temperature for the analogue (y-axis) at the age of the Tigalmamine sample (x-axis). The marker size in this plot corresponds to the chord distance between modern and fossil pollen assemblage. I.e., the larger the dot, the closer (and more important) the analogue. The dashed line shows the weighted average of all the climate analogues per sample. The age of each Tigalmamine sample is shown with the vertical lines at the bottom of the plot. Red crosses in the lower plot show the Tigalmamine core top sample that has been used as an analogue in 58 out of the 110 samples.}
	\label{fig:gridding-site-analogues}
\end{figure}

We chose the pollen record of Tigalmamine in Morocco (32.9N, 5.34W, 1626m) to evaluate our method. The site was first studied by \cite{LambKaars1995}, and the pollen data was downloaded from the European Pollen Database. The chronology and choice of control points used here is that from Giesecke et al \citep{GieseckeDavisBrewerEtAl2013}. The site is well dated with 11 radiocarbon dates, and spans the entire Holocene with 110 samples. The data has been used for a previously published pollen reconstruction based on the modern analogue method \citep{CheddadiLambGuiotEtAl1998}, although this study used a calibration dataset that included modern pollen samples from Morocco that have subsequently been found to have geolocation errors \citep{DavisZanonCollinsEtAl2013}. None of these problematic modern samples have been used in our analysis. 

The site (red cross in figure \ref{fig:gridding-site-analogues}) is located on the southern edge of our study region in an area with a montane Mediterranean vegetation and climate. The Mediterranean has traditionally been considered to be a particularly challenging environment for pollen-based reconstructions because of the effects of long term human impact, and the interplay of precipitation and temperature on vegetation distribution. The fossil pollen record of Tigalmamine shows a mainly forested montane Mediterranean assemblage throughout the Holocene, dominated by evergreen oak, but with an important transition between the early Holocene and late Holocene marked by a change from deciduous Oak to Cedrus (see the pollen diagram in \cite{CheddadiLambGuiotEtAl1998}). The occurrence of Cedrus represents an interesting challenge for any pollen climate transfer function, since this particular taxa is limited in its distribution (and in our calibration dataset) to Morocco and the Lebanon region, while all of the other taxa in the assemblage are widely distributed across the Mediterranean. The strong presence of evergreen Oak also makes the site interesting, because although this taxa is mainly associated with the Mediterranean region, its distribution extends all the way up the west coast of France to Brittany.

Figure \ref{fig:gridding-site-analogues} illustrates these challenges for the particular site. The climate analogues (see next section \ref{sec:gridding-mat}) span a large summer temperature regime of about 10 degrees, from 15 to 25 °C. The upper temperature range is dominated by analogue climates from Spain (orange) which in general shows the highest number analogue matches. The lower temperature regime is dominated by Moroccan samples (green) that are of particular importance during the late Holocene due to the above mentioned presence of Cedrus. During the transition in the mid-Holocene, analogues from across the Mediterranean play a more important role, in particular from Greece, Italy and Turkey. The early Holocene is dominated by modern samples from Spain, but with a much wider and more uniform temperature regime.

The weighted average of the analogues (black dashed line in figure \ref{fig:gridding-site-analogues}) is in general about one to two degrees lower than the one in \cite{CheddadiLambGuiotEtAl1998} (very likely due to the above-mentioned erroneous calibration data they used). The trends are however similar: Higher temperatures in early Holocene  (the \textit{spanish analogues} dominate) with a drop around 6k BP (Moroccan climates). Our weighted average however also shows a clear increase during the past 2000 years, again driven by spanish analogues.

The climatic and geographic space that is covered by the analogues is further discussed in section \ref{sec:gridding-temperature-sampling}.

\subsection{Site-based holocene temperature estimates}  \label{sec:gridding-mat}
A standard approach for site-based climate reconstruction from fossil pollen assemblages is the so-called \glsfirst{mat} (also called $k$-nearest neighbors). This technique estimates the climate of the fossil sample as the (weighted) climate average of the most similar modern samples (i.e. the closest modern analogues). It has the major advantage that it requires little parameterization efforts and can be applied over a large spatial area that covers many different climate regimes \citep{MauriDavisCollinsEtAl2015}. We apply this method but vary it in our probabilistic setup, such that it better represents the spatial domain of the modern analogues.

For this purpose, we follow the standard approach and assign a \gls{jja} temperature to each modern calibration sample (figure \ref{fig:gridding-modern}), taken from the corresponding grid cell in the WorldClim dataset, version 2 at 30 seconds \citep{FickHijmans2017}.

In the next step every pollen assemblage is transformed from raw counts to percentages, based on the total sum of terrestrial pollen counts in the sample. In order to measure the similarity between a (transformed) fossil pollen assemblages $\left\lbrace f_{i}\right\rbrace$ and modern pollen assemblage $\left\lbrace m_{i}\right\rbrace$ with use squared-chord distance from the R package \textit{rioja} \citep{Juggins2017}, defined as

\begin{equation*}
d = \sum_{i}\left(\sqrt{f_{i}} - \sqrt{m_{i}}\right)^2
\end{equation*}

This is done for every modern and fossil sample in the database. The standard, non-probabilistic setup would now compute the climate of the fossil sample as the mean climate of the $k$ closest analogues (e.g. $k = 6$), eventually weighted by their corresponding distance $d$. There are many variations of this technique (see for example \cite{BirksHeiriSeppaeEtAl2010}, including various measures of similarity\addref, choices about $k$\addref, the maximum allowed distance $d$ between modern and fossil assemblage\addref, subsampling of the calibration dataset to avoid spatial autocorrelation\addref[Guiot and de Vernal, 2011; Telford and Birks, 2009, 2005], and by grouping pollen taxa into so-called plant-functional types (PFTs) \citep[e.g.]{DavisBrewerStevensonEtAl2003, MauriDavisCollinsEtAl2015}. They all, however, have in common that the categorical, multi-modal distribution of the climate of the modern analogues is oversimplified into a unimodal distribution represented by the mean of the analogue climates. Therefore, in our ensemble approach, we explicitly do not take the mean but sample the climate of the analogues directly. This is further discussed in the methods section \ref{sec:gridding-temperature-sampling} and \ref{sec:gridding-site}.


\subsection{Age uncertainties}  \label{sec:gridding-ageunc}
In addition to the methodological uncertainties of the climate reconstruction method (previous section \ref{sec:gridding-mat}), we provide a framework to handle dating uncertainties. During the gridding step (see next section \ref{sec:gridding-gridding}), every sample is weighted by the age difference to the target reconstruction age. The previous studies by \cite{DavisBrewerStevensonEtAl2003} and \cite{MauriDavisCollinsEtAl2015} do not take this uncertainty, that can be as high as multiple centuries, into account although they influence the gridded temperature reconstruction.

The reason is a systematic problem of pollen samples that we overcome here with the recent developments in the pollen community. In palynology, each sample in a sediment core is is dated using a so-called age-depth model, a function that maps each depth of the sediment core to an age. This function is based on a few chronological control points where the age has been determined instrumentally (for lake sediments in the Northern Hemisphere, these are commonly radiocarbon ($^{14}$C dates) and interpolates/extrapolates to the depths of the sample locations. Various methodologies exist to define these age-depth models, ranging from simple linear interpolation methods \citep{Bennett1994} to the more recently developed bayesian techniques of the Bchron \citep{HaslettParnell2008} and BACON \citep{BlaauwChristen2011} models.

The early approaches have been proven to provide unreliable uncertainty estimates \citep{TelfordHeegaardBirks2004} and there has been no standardized way to report the uncertainties, if they are reported at all. For this reason we (and previous studies) cannot rely on the age uncertainties reported in the pollen database. An alternative approach is to recalculate the chronology for every dataset in the database \citep[see][for instance]{Goring2019}, but this also requires parameterization for reliable uncertainties and goes beyond the scope of this study.

Instead, we follow an approach that is based on two aspects: age uncertainties are higher for older samples, and samples that are farther away from the radiocarbon dates (i.e. chronological control points). Additionally, samples behave differently if the sample is surrounded by two chronological points (i.e. the sampe age is interpolated) or not (sample age is extrapolated). These relationships are illustrated in figure \ref{fig:gridding-univariate-unc}, based on all datasets (ca. 30'000 samples) from the Neotoma paleoecology database \citep{WilliamsGrimmBloisEtAl2018} that have age-depth models estimated with BACON, a model that has been proven to provide more reliable age uncertainty estimates \citep{TrachselTelford2016}. These uncertainties in Neotoma are reported as two sigma confidence intervals of lower and upper sample age bounds, but for the sake of implementation (section \ref{sec:gridding-age-sampling} assumes a normal distribution), we use the one sigma uncertainty of the maximum of the two deviations. The grayscale density plots in the background shows the high dispersal of the data and the number of samples decreases strongly with higher distance to the control point or older samples (red lines). Nonetheless, the mean of the data (blue lines) reveals the increasing nature of both relationships, as mentioned before.

Figure \ref{fig:gridding-univariate-unc} also shows two models that have been fitted to the data. The first one is a standard simple univariate linear model $y = a + b\cdot x$ (orange line). This model already simulates the increasing trend of both variables although it does not capture the non-linear relationship between age and age-uncertainty. A possible reasons for this non-linearity might be the time-dependency of the radiocarbon calibration curve and it's associated errors. This gives the motivation to use a constrained linear \glsfirst{gam}, a smooth semi-parametric model of the form

\begin{equation*}
	\mathbb{E}[y|X] = \beta_0+f_1(X_1)
\end{equation*}

in the univariate case, or

\begin{equation*}
\mathbb{E}[y|X] = \beta_0+f_1(X_1)+f_2(X_2)
\end{equation*}

in the bivariate case. The feature functions $f_{1,2}$ are based on penalized B splines with a constraint for monotonic increasing, $\mathbb{E}[y|X]$ is based on a normal distribution and has been fitted with the \textit{pyGAM} software package \citep{ServenBrummittAbedi2018}. This model enables to better simulate the non-linear features as can be seen with the green lines in figure \ref{fig:gridding-univariate-age-unc}.

These results approve the initial hypotheses and justify the choice of a bivariate \gls{gam} for predicting age uncertainties based on the distance to the chronological control point, and the age of the sample. The two models, together with a bivariate simple linear regression model, and again for interpolated and extrapolated samples, are shown in the central column of figure \ref{fig:gridding-bivariate-age-unc}. Both model classes (simple linear and \gls{gam}) are able to reproduce the general shape of the observed data, although the \gls{gam} better resolves the non-linear relationship between the three variables.

The final uncertainties, predicted for the data set presented in the previous section \ref{sec:gridding-polnet}, are shown in the supplementary figure \ref{fig:gridding-age-uncertainties}.

\begin{figure}
	\captionsetup{width=\linewidth}
	\includegraphics[width=\linewidth]{gridding-figures/univariate-models.pdf}
	\caption[Univariate age uncertainty models]{Univariate regression plots of (first and third) distance to chronological points, and (second and fourth) age to the one sigma dating uncertainty of the sample. The upper two plots contain only interpolated samples (i.e. samples that lie between two chronological control points), the lower extrapolated samples. Blue lines show the mean age uncertainty for the given distance (age). Orange and green lines show the linear and \gls{gam} fits of distance (age) to age uncertainty, and red lines show the number of samples for a given distance (age). The grayscale plot in the background shows a two-dimensional histogram (density plot) to illustrate the underlying data of the fits. For the purpose of a better visualization, each vertical bin of this histogram has been normalized to one. Means, counts and histogram are all based on 100 year bins in distance (age). The fits are estimated based on the unbinned data, the source data are all Neotoma datasets with BACON-based age-depth models. Note the logarithmic scale of the right count axis on the first and third plot.}
	\label{fig:gridding-univariate-age-unc}
\end{figure}

\begin{figure}
	\includegraphics[width=\linewidth]{gridding-figures/bivariate-models.pdf}
	\caption[Univariate age uncertainty models]{Bivariate models of age uncertainty. The top row shows interpolated samples (i.e. samples that lie between two chronological control points), the bottom row extrapolated samples. Plots in the left column show the observed data (samples of the Neotoma database with BACON-based age-depth models), central and right columns show the simulations of bivariate linear \glspl{gam} or bivariate linear regression models respectively. y-axes are the distance to the closest chronological control point, x-axes are the age of the sample, both binned into 100-years intervals. The color coding of each 100 by 100 years grid cell is based on the mean age uncertainty of all samples within this cell.}
	\label{fig:gridding-bivariate-age-unc}
\end{figure}

\section{Method}  \label{sec:gridding-method}
With the intrinsic methodological uncertainties of climate and dating in mind, we present a new ensemble-based approach on gridding the reconstructions from the individual sites. Each ensemble member is generated with an randomized sample ages and climate, derived from the corresponding uncertainty measures (see previous sections \ref{sec:gridding-mat} and \ref{sec:gridding-ageunc}), with additional constrains arising from the integrity of the individual dataset (sediment core). We explain these in more details in sections \ref{sec:gridding-age-sampling} and \ref{sec:gridding-temperature-sampling}. The final gridding step for each ensemble member is based on a modified setup of \cite{MauriDavisCollinsEtAl2015}, but can also be extended with other interpolation algorithms, as described in section \ref{sec:gridding-gridding}). We implemented the method as the python package \textit{pyleogrid} that efficiently scales to large datasets and ensemble sizes, and shortly describe it in section \ref{sec:gridding-package}.

\subsection{Constrained age sampling}  \label{sec:gridding-age-sampling}

\begin{figure}
	\includegraphics[width=\linewidth]{gridding-figures/age-sampling-methods-realized.pdf}
	\caption[Scaled histograms of age sampling methods]{Histograms of standardized age sampling methods for the site in section \ref{sec:gridding-sample-site} with an ensemble size of 10'000. Every sampled age has been centered at the reported age of the corresponding sample and scaled by its age uncertainty. The black line shows the unconstrained distribution (a standard normal with a standard deviation of 1), the other histograms show the realized distributions for each of the age sampling methods (section \ref{sec:gridding-age-sampling}). Note that \textit{random sort} and \textit{Gibbs} histograms highly overlap.}
	\label{fig:gridding-age-sampling-methods}
\end{figure}

Every dataset has an intrinsic monotonicity constrain that the sample deeper down the core has an older age. An inversion of this constrain is very rare and is usually visible in the stratigraphy of the core, such that affected samples are ruled-out before. As such, a classic unconstrained sampling of ages\footnote{\label{foot:unconstrained-note}We call it the unconstrained distribution for convenience, but keeping in mind that every sampled age has to be older than -70 yr cal BP.} using a normal distribution centered at reported sample age and a scale corresponding to the estimated age uncertainty (section \ref{sec:gridding-ageunc}) violates this constrain. Samples are inverted in such a case when their uncertainty intervals overlap and as such the individual ensemble member would not maintain the integrity of the individual core. We illustrate an example for such a core in section \ref{sec:gridding-site}.

\textit{pyleogrid} therefore implements different variants of this constrain with the Gibbs sampling being the one that is finally used.

\subsubsection{The intuitive approach}
The most intuitive approach is to randomly draw a sample age and constrain the age of the neighboring sample with it. This can be done in a \textit{forward} manner, such that every older sample has to be older than the previous younger sample, or in a backward manner, i.e. the younger sample has to be younger than the neighboring older sample. We will show in the paragraphs below that this method is not working, nevertheless we mention it here because of the intuitivity of the approach and because the reason for the failure is non-trivial.

As such, we demonstrate three different algorithms:

\begin{description}
	\item[forward] Starting with an unconstrained age distribution for the youngest sample in the core, every consecutive sample has to be older than the previous (i.e. the method works forward in age, but backward in time
	\item[backward] Starting with an unconstrained age distribution for the oldest sample in the core, every consecutive sample has to be younger than the previous (i.e. the method works backward in age, but forward in time)
	\item[random start] Starting with an unconstrained age distribution of a random sample in the core, we apply the \textit{backward} algorithm for younger and \textit{forward} algorithm for younger samples.
\end{description}

As such, \textit{forward} and \textit{backward} algorithms always start with an unconstrained age distribution of the youngest (oldest) sample for every ensemble member. Within the \textit{random start} algorithm, every sample gets the chance to start with an unconstrained age distribution, because the starting point is random for every ensemble member. The constrained age distributions for the consecutive samples are implemented as truncated normal distributions.

The resulting age distributions from the three algorithms are shown in figure \ref{fig:gridding-age-sampling-methods}, together with another method, that is described later in this section. The figure shows the sampled age distributions by the various above-mentioned sampling methods for the site described in section \ref{sec:gridding-sample-site}. To make these age distributions comparable, we transformed them to a standard normal distribution (visualized as the unconstrained distribution in figure \ref{fig:gridding-age-sampling-methods}) prior to visualization, by subtracting the reported age and dividing by the estimated age uncertainty of the corresponding sample. It is obvious from this figure that all of the above-mentioned algorithms produce an artificial bias to the age distribution. The \textit{forward} approach pushes the samples to the upper tail of the distribution, the \textit{backward} approach pushes everything to the lower tail. The \textit{random start} method produces a bimodal distribution with peaks at the upper and lower tail.

This is also shown with three exemplary samples from the site in the supplementary figure \ref{fig:gridding-age-example-distributions}. The forward method works well for the young sample but pushes all older samples to the upper tail of their distribution, The backward method does the opposite and the random sort method creates a bimodal distribution for the sample in the center of the core, and backward behaves like the forward (backward) algorithm at the older (younger) part of the core.

We explain this initially unexpected results with the overlapping age uncertainties in the core. The site that we describe here has 110 samples. As such, the probability that one sample draws a random age at the lower or upper tail of the distribution is very high. Now, most of the dating uncertainty intervals overlap and this forces all the consecutive samples to the tail of their age distributions. Another problem, that is not shown here, arises from the differing sizes of the age uncertainties which highly depends on the distance to the chronological control point (see section \ref{sec:gridding-ageunc}). This can also lead to unsatisfiable requirements, if one sample is close to a control point (and as such has a lower age uncertainty) and the previous sample has been pushed far outside of the 95\% confidence interval.


\subsubsection{The random sorting approach}

These strong biases of the intuitive approach led to another method, that we also show in red in figure \ref{fig:gridding-age-sampling-methods} and supplementary figure \ref{fig:gridding-age-example-distributions}, the \textit{random sort} method. This method consists of two steps: in the first step we draw random age for each sample based on its unconstrained distribution\textsuperscript{\ref{foot:unconstrained-note}}. In the second step, we order these random ages while maintaining the order of samples in each dataset. As such, we assign an age to each sample that is not necessarily drawn from its own distribution, but rather from the one of a neighboring sample. When samples overlap, this then truncates the tails of realized distribution and effectively decreases the reported age uncertainty, as can be seen in the figures \ref{fig:gridding-age-sampling-methods}, \ref{fig:gridding-age-example-distributions}. This approach is mathematically difficult to justify because it violates the common methodology that each sample has a unique confidence interval that it needs to explore. Therefore the method might introduce some hidden biases in the sampled distributions that are difficult to quantify. Nevertheless, the algorithm is very fast and much closer to the desired joint distribution, than the previous \textit{intuitive} approach. We therefore implemented another Gibbs sampling algorithm.


\subsubsection{The Gibbs sampling approach}

\begin{figure}
	\includegraphics[width=\linewidth]{gridding-figures/full-realized-age-distribution.pdf}
	\caption[Realized age distribution for the entire dataset]{Realized age distribution for the entire dataset (section \ref{sec:gridding-polnet}) with the \textit{random} method (section \ref{sec:gridding-age-sampling}). The individual sample distributions have been centered and scaled as in figure \ref{fig:gridding-age-sampling-methods}.}
	\label{fig:gridding-full-age-distribution}
\end{figure}

\begin{algorithm}[h]
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\caption[Classic MCMC approach]{Classic \gls{mcmc} approach. $\mathcal{N}(\mu, \sigma)$ denotes the normal distribution with location parameter $\mu$ and shape parameter $\sigma$.}
\label{a:gridding-mcmc}
\begin{algorithmic}[1]
	\STATE Set $i = 0$
	\STATE Set $\boldsymbol{\mu}$ as vector of the reported ages in $dataset$
	\STATE Set $\boldsymbol{\sigma}$ as vector of estimated age uncertainties		
	\STATE Set $\mathbf{a}$ (the target age vector) to be of length $\boldsymbol{\mu}$
	\WHILE{$i < 1$ \OR \NOT $is\_monotonic(\mathbf{a})$}
	\STATE $\mathbf{a} = \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma}^2)$
	\STATE Set $i = i + 1$
	\ENDWHILE
\end{algorithmic}
\end{algorithm}

The biases of the above-mentioned algorithms led to the development of a \gls{mcmc} sampling algorithm. A standard \gls{mcmc} approach, is to draw a set of random ages for all unconstrained sample distributions in a core at once, until this set of ages satisfies the monotonicity criterion. For one realization of the ages $\mathbf{a}$ in a given dataset, this is described with the pseudo-code in algorithm \ref{a:gridding-mcmc}. This standard approach however did not find a monotonic solution within ten million iterations for a high-resolution site such as it has been used in the previous section. 

Therefore we decided to implement a Gibbs sampler, an algorithm that is commonly used in Bayesian inference to obtain a sequence of observations in order to approximate a multivariate probability distribution, when this joint distribution is unknown and/or cannot be sampled directly. In our case, this distribution if the distribution of all sample ages in one dataset, where each sample age is conditioned by it's younger and older neighbor. Let $\mathbf{a}^{(i)} = \left(a^{(i)}_1, a^{(i)}_2, \ldots a^{(i)}_N \right)$ be the $i$-th realization of the ages in a dataset with $N$ reported ages $\boldsymbol{\mu}$ and estimated age uncertainties $\boldsymbol{\sigma}$. We start with $\mathbf{a}^{1} = \boldsymbol{\mu}$. For a given $i$ and sample $j\leq N$ in the dataset, we then draw a random number for the sampled age $a^{i}_j$ conditioned by the younger age in the same realization ($t_0 = a^{i}_{j-1}$) and the older age in the previous realization ($t_1 = a^{i-1}_{j+1}$) via

\begin{equation}
	a^{i}_j = \mathcal{N}^{t_1}_{t_0}(\mu_j, \sigma_j^2)
\end{equation}

where $\mathcal{N}^b_a(\cdot, \cdot)$ denotes the truncated normal distribution with lower limit $a$ and upper limit $b$. As such, the first realizations are conditioned by the reported ages and are commonly ignored (the so-called \textit{burn-in} period). In our case, we set this number to 1000. 
Additionally, every sample is conditioned by the previous realization, which creates an autocorrelation between the different realizations. It is therefore a common strategy to only keep every $n$-th realization. An autocorrelation analysis on the different samples in our demonstration site (section \ref{sec:gridding-sample-site}) revealed that autocorrelation gets negligible after ten realizations. Hence, we only keep every tenth realization until we have the desired number of total realizations.

As can be seen in figure \ref{fig:gridding-age-sampling-methods} and \ref{fig:gridding-age-example-distributions}, the outcomes are very close to the above mentioned \textit{random sort} approach. However, a look into the realized distribution of the last sample in figure \ref{fig:gridding-age-example-distributions} reveals a negative bias of the distribution sampled with the \textit{random sort} approach.

The realized (and standardized) distribution of the entire database presented in section \ref{sec:gridding-polnet} is finally shown in figure \ref{fig:gridding-full-age-distribution}. The comparison with the unconstrained distribution in this figure highlights the need for a constrained sampling because the latter significantly reduces the width of the distribution.

\subsection{Temperature sampling}  \label{sec:gridding-temperature-sampling}

\begin{figure}
	\includegraphics[width=\linewidth]{gridding-figures/temp-sampling-methods-realized.pdf}
	\caption[Scaled histograms of temperature sampling methods]{Histograms of standardized temperature sampling methods for the site in section \ref{sec:gridding-sample-site} with an ensemble size of 10'000. As in figure \ref{fig:gridding-age-sampling-methods}, every sampled temperature has been centered at the weighted average of the corresponding modern analogues and scaled by the corresponding weighted standard deviation. The black line shows the unconstrained distribution (a standard normal with a standard deviation of 1), the other histograms show the realized distributions for \textit{random start} and \textit{Gibbs} temperature sampling method (section \ref{sec:gridding-age-sampling}). \textit{forward} and \textit{backward} methods are almost similar to the results of the \textit{random start} approach and therefore not shown.}
	\label{fig:gridding-temp-sampling-methods}
\end{figure}

As already mentioned in \ref{sec:gridding-mat}, our sampling approach does not use the temperature and uncertainty reported for every single variable. Instead, it samples the underlying distribution. As such, out method can be adapted to multiple site-specific reconstruction methods, such as weighted averaging (WA), weighted-averaging partial-least squares (WAPLS) \citep{BirksBraakLineEtAl1990, BraakJuggins1993} or other approaches \citep[e.g.][]{BirksHeiriSeppaeEtAl2010, BrewerGuiotBarboni2007, Juggins2013}. In this study, we use a \gls{mat} approach (see section \ref{sec:gridding-mat}) and sample the discrete set of climate analogues for each sample. The probability to select an analogue (i.e. it's weight) is thereby determined by the chord distance between the fossil and modern pollen assemblages. The closer the assemblages (relative to the other potential analogues), the higher the weight.

This methodology is substantially different from the standard approach, such that is takes the multimodality of the analogues into account, whereas the standard appraoch (weighted average of the $k$ closest analogues) estimates a unimodal distribution. It additionally better represents the discrete nature of the analogue approach wheras the standard method intrinsically assumes a continuity in the distribution. In fact, only a small part of the available climate space is actually represented by the modern analogues. The 5'500 modern analogues for Tigalmamine, for instance (110 samples with 50 analogues each), are represented by only 240 distinct modern pollen samples with only 131 distinct \gls{jja} temperatures and they eventuelly span a large climate space (see figure \ref{fig:gridding-site-analogues}).

\subsubsection{Climatic constrain}
The latter gives the motivation for a climatic constrain that ensures the integrity of the individual dataset. It is, for instance, impossible that two samples from the same dataset but 200 years apart experience a temperature difference of five degrees or more between each other. This is, however, a possible combination, considering the underlying set of analogues (see figure \ref{fig:gridding-site-analogues} for instance). We therefore perform a constrained sampling, as in section \ref{sec:gridding-age-sampling}, and implement a fixed temperature threshold $T$. Every sampled analogue in each dataset (i.e. every choice of the discrete distribution for each pollen sample) is constraint to not differ by more than $T$ degrees celsius from its surrounding samples. The exact choice of $T$ is a critical assumption and has a major impact on the realized temperature distribution for each sample. We decided for a very conservative estimate of five degrees, which is only applied if the samples do not differ by more than 1000 years. These choices are further discussed in section \ref{sec:gridding-results}.

In the remainder of this section, we focus on the implementation of this conditional sampling, because of its substantial impact on the realized distribution, as already shown for the sampled ages in section \ref{sec:gridding-age-sampling}. We briefly discuss the same approaches as in section \ref{sec:gridding-age-sampling} (without the \textit{random sort} algorithm because we do not enforce monotonicity here). The core of the method is the same for all approaches: If a climate analogue differs by more than $T$ degrees from the temperature of the conditioning sample, its probability is set to zero. The choice about the \textit{conditioning sample} is dependent on sampling algorithm. Here, we discuss following methods:

\begin{description}
	\item[forward] The temperature of every older sample must not differ by more than $T$ from its younger sample
	\item[backward] The temperature of every younger sample must not differ by more than $T$ from its older sample
	\item[random start] Starting with a random sample in a data, we apply the forward method to older and the backward method to younger samples
	\item[Gibbs] The choice for each sample is constrained by the younger sample and the older sample from the previous realization of the dataset.
\end{description}

We described these algorithms already in detail in section \ref{sec:gridding-age-sampling} and therefore focus only on the comparison of results. The only difference is that now, without the monotonicity constrain, \textit{forward} and \textit{backward} methods give the same result as the \textit{random start} method. Therefore we will only focus on the last two methods.

Figure \ref{fig:gridding-temp-sampling-methods} shows the realized distributions for the two methods. As in the corresponding figure for the age sampling (figure \ref{fig:gridding-age-sampling-methods}), we subtracted the weighted average of the climate analogues of the corresponding pollen sample by each of the randomly sampled temperature values, and afterwards divided by the weighted standard deviation, in order to make the drawn temperature values at the different ages comparable. 

\begin{itemize}
	\item Sampling of analogue climates weighted by squared chord distance
	\item Can also use different methods (WAPLS, etc.)
	\item Random starting point
	\item Mask analogues that have a temperature distance more than 5°C??? From the previous/earlier sample – test this
\end{itemize}

\subsection{Gridding}  \label{sec:gridding-gridding}
\begin{itemize}
	\item 3D of climate (not anomaly)
	\item Distance in time through weighting
	\item Paleo-Elevation (ICE-6G)
	\item Can use any other method than tps
\end{itemize}

\subsection{Implementation}  \label{sec:gridding-package}

\section{Results}  \label{sec:gridding-results}

\subsection{Site-based realized climate reconstruction: a use-case} \label{sec:gridding-site}
\todo[inline]{Reconstruction of entity 11390}

\section{Discussion}  \label{sec:gridding-discussion}

\begin{itemize}
	\item Maps of reconstruction
	\begin{itemize}
		\item How high are the uncertainties
	\end{itemize}
	\item Questions: 
	\begin{itemize}
		\item How does the uncertainty evolve with distance to the samples
		\begin{itemize}
			\item At map boundaries
			\item In gaps within the data
		\end{itemize}
	\end{itemize}
	\item How consistent is the interpolation uncertainty (from Tps) within the ensemble?
\end{itemize}


\section{Conclusions}  \label{sec:gridding-conclusions}

\clearpage

\begin{subappendices}
	\section*{Supplementary material}
	
	\section{Estimated age uncertainties}  \label{sec:gridding-suppl-age-uncertainties}	
		\begin{figure}[!h]
			\includegraphics[width=\linewidth]{gridding-figures/realized-age-uncertainties.pdf}
			\caption[Estimated age uncertainties]{Estimated age uncertainties for the Eurasian dataset from section \ref{sec:gridding-polnet} with the same formatting as in figure \ref{fig:gridding-bivariate-age-unc}.}
			\label{fig:gridding-age-uncertainties}
		\end{figure}
	
	\clearpage

	\section{Example of generated age distributions} \label{sec:gridding-suppl-age-example-distributions}
		\begin{figure}[!h]
			\includegraphics[width=\linewidth]{gridding-figures/age-sampling-methods-use-case.pdf}
			\caption[Example of sampled distribution]{Example of three samples from the site in section \ref{sec:gridding-site} and their realized distributions. Sampling algorithms are explained in section \ref{sec:gridding-age-sampling}. Top plots show the box plots of the realized distribution that are visualized with a kernel density estimate in the lower row.}
			\label{fig:gridding-age-example-distributions}
		\end{figure}

\end{subappendices}

\printbibliography[heading=subbibintoc]

\end{refsection}